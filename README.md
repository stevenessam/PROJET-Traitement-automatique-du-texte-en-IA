# TATIA - Projet de Classification et Analyse des Sentiments dans les Critiques de Films

 ---

## Master 1 Informatique 2023/2024 : Traitement automatique du texte en IA

### Étudiant:

- **ESSAM EDWAR AZIZ Steven (22309059)**

---

**JEU DE DONNEES** : [IMDB Dataset of 50K Movie Reviews | Kaggle](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)

---

# Étapes du projet :

Étape 1 : Chargement du fichier CSV dans un DataFrame

Étape 2 : Analyse exploratoire des données

- 2.1 Examiner la structure des données

- 2.2 Vérifier la distribution des classes (sentiments)

- 2.3 Visualiser des statistiques descriptives

Étape 3 : Prétraitement des données

- 3.1 Suppression des balises HTML du texte des critiques

- 3.2 Conversion du texte en minuscules

- 3.3 Suppression de la ponctuation

- 3.4 Suppression des stop words

- 3.5 Tokenisation

- 3.6 Lemmatisation ou racinisation des mots

Étape 4 : Division des données

Étape 5 : Vectorisation du texte

Étape 6 : Construction du modèle

Étape 7 : Évaluation du modèle

Étape 8 : Interprétation des résultats

Étape 9 : TEST - Application du modèle SVM sur de nouvelles données

---

Étape 10 : Comparaison avec d'autres algorithmes

- 10.1 - Implémentation du modèle Random Forest

- 10.1 - Évaluation du modèle Random Forest

- 10.1 - TEST - Application du modèle Random Forest sur de nouvelles données

- 10.2 - Implémentation du modèle Naive Bayes

- 10.2 - TEST - Application du modèle Naive Bayes sur de nouvelles données

    

---

Étape Finale : Comparaison des trois algorithmes

- Matrices de confusion

- Précisions des modèles

---

Conclusion - Comparaison des trois algorithmes

Trois modèles d'apprentissage pour l'analyse des sentiments ont été implémentés et évalués : SVM, Random Forest et Naive Bayes. Les modèles ont été entraînés sur les données d'entraînement, évalués sur les données de test et testés sur de nouvelles critiques.

Le modèle SVM a obtenu la meilleure précision parmi les trois modèles, avec une précision de 88.62%. Le modèle Random Forest a obtenu une précision de 84.84%, tandis que le modèle Naive Bayes a obtenu une précision de 85.13%.
